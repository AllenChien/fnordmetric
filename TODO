rename rowsink to virtualtable
rename seriesadapter to chartbuilder
cli output format
linechart multiple series
linechart string axis
distributions
middle axis
bar/point labels
heatmaps
histogram
missing data / interpolation gap
proper error message for missing table import

v2.0.0a
  - all examples working
  - bar, area, line, pie, number chart
  - documentation as per TOC complete
  - full sql selects, joins working
  - csv backend complete
  - cli interface
  - TimeDomain!
  - max interpolation gap -> draw as missing data

v2.0.0b
  - mysql backend
  - simple web interface (interactive query UI generates embed html snippets)
  - simple dashboards working
  - simple interactive charts (hover tooltips)
  - histogram

v2.1.0
  - statsd/graphite backend
  - postgresql backend
  - gannt charts
  - sparklines? (multi svg output)
  - stacked area charts
  - smooth paths
  - legend!
  - gauges, heatmaps, boxplot, error bars 
  - middle axis
  - annotations / deploy lines
  - query cache
  - dashboard edit ui: html source
  - dashboard edit ui: wysiwyg







RANDOM IDEAS

- moving avg, etc
- candlestick

fnordmetric web:
    $ fnordmetric --web 8080   # standalone webserver on port 8080
    $ fnordmetric --cgi        # mount me as cgi script!


rename:
  canvas -> chart
  resultlist -> table


examples from csv file with temp measurements per time/city -> timelines, range
bar charts etc...

bar chart examples:
  * horizontal
  * vertical
  * horizontal with labels outside
  * horizontal with labels inside
  * vertical with negative values
  * zero-centered horizontal ranges
  * multiseries unstacked
  * multiseries stacked
  * histogram
  * multiple y axis

point chart examples:
  * single 2d series
  * point types, size
  * multi 2d series
  * multi 3d series
  * negative values
  * middle axis

--- axis expr can be a tuple!!. e.g for error bars or area

-- draw a graph with explicit axis definition
DRAW LINE CHART;

SERIES experiment XAXIS fu YAXIS bar FROM
  SELECT fu, bar FROM table1;


-- draw a graph with different y scales per series
DRAW LINE CHART;

SERIES experiment YSCALE 0, 100 FROM
  SELECT x, y FROM table1;

SERIES experiment YSCALE 0, 500 FROM
  SELECT x, y FROM table2;


-- draw a graph with dynamic YSCALE
DRAW LINE CHART;

SERIES experiment YSCALE 0, max(y) * 1.5 FROM
  SELECT x, y FROM table1;

SERIES experiment YSCALE 0, max(y) * 1.5 FROM
  SELECT x, y FROM table2;

Examples page with examples left: query, right: output and link to examples/
folder with source data!

eMail contributers and long time followers "FnordMetric <3 username"


-> msync
-> import freelist properly
-> MmapPageManager, MallocPageManager, InMemoryDatabase, FileBackedDatabase
-> crc32 instead of fnc32 for checksums?
-> file lock on open
-> proper error handling

You can run it as a standalone timerseries database or as a network of distributed
data collection agents. SQL Syntax, statsd support, c++, bindings for x,z,y jadda
jadda

FnordMetric is heavily optimized for sequential queries and aggregations over
time ranges. This means running something like "give me the slowest pages by
90th percentile latency for every 10 minute window in the last 3 days" is pretty
fast, whereas something like "give me a whole stream with thousands of rows but
reorder it by some custom" field is better suited for a regular database.

- streaming queries that output a continiously changing dataset
- standing queries (< streaming queries) that output the data into a new stream
  as it is generated
- streaming queries can't have: order by -- can they?
- no sub-query support! (if you need sub queries what you are trying to do is
probably better suited for a regular database anyway)

Execution Flow:

  {
     Scan+Filter,
     Aggregate
  }
  Having
  Re-Order
  Limit, Offset


-- Select number of http error codes in the last hour
SELECT http_status, count(http_status) from http_requests
  WHERE time > -24hours
  GROUP BY http_status;
-- AGGREGATE_LOCKSTEP;

-- Select 90th percentile latency in the last day
SELECT percentile(latency, 90) from latency_metric WHERE time > -24hours;
-- SCAN_LOCKSTEP

-- SELECT error rate with two metrics and a 5 min window
SELECT
  time,
  ((delta(succesful_requests.count) / delta(errors.count)) * 100) as error_rate,
  FROM successful_requests, errors
  WHERE time > -24hours
  GROUP BY TIME_WINDOW(5 minutes);
-- AGGREGATE_TIME_WINDOW

-- SELECT top 10 slowest pages yesterday by 90th percentile latency
SELECT
  url, percentile(90, latency) as 90thpercentile_latency
  FROM request_log
  WHERE time > 24hours
  GROUP BY url
  ORDER BY 90thpercentile_latency DESC
-- SELECT all pages yesterday with a 90th percentile latency > 1000ms
SELECT
  url, percentile(90, latency) as 90thpercentile_latency
  FROM request_log
  WHERE time > 24hours
  GROUP BY url
  HAVING 90thpercentile_latency > 1000;

-- SELECT 90thpercentile page latency for three pages in 5 min windows
SELECT
  time, url, percentile(90, latency) as 90thpercentile_latency
  FROM request_log
  WHERE time > 24hours
  WHERE url IN ("/mypage1", "/mypage2", "/mypage3")
  GROUP BY TIME_WINDOW(5minutes), url;

-- COUNT number of events per time period
SELECT count(*) FROM metric GROUP BY TIME_WINDOW(5minutes);

-- SELECT holtwinters forecast for a metric value
SELECT real_value, holtwinters_forecast(real_value)
  FROM metric
  WHERE time > -24hours AND time < +24hours;

-- JOIN two streams on a non time parameter
-- SELECT http error rate from one metric for yesterday in 5 min windows
-- SELECT http error rate from one metric for yesterday gross


-> Concepts: Stream, Agents vs Server, Retention Policy

-> functions: sum, avg, percentile, mean, variance, stddev, delta, nth_derivate,
              holtwinters

-> msync safety mode: relaxed (consistent but might loose data), conservative
                      (msync async) and paranoid (msync sync)

-> implicit fields: time, agent, offset

-> UI menu: query / streams
-> streams: local/remote. disk usage, replication status, retention, etc
-> query ui: tabs for: html req equivalent, html embed, etc
-> query safety mode: on/off (check row checksums)
-> malloc page manager
-> example:
  * getting started standalone:
     * create http_reqs stream with statuscode, count
     * select select http error rate
  * getting started distributed
     * agents have metrics with http req time distribution and url
     * graph global req time distribution
     * graph 90th percentile req time per agent
-> renice query threads in agents?
-> push query down into backend
-> agents that run queries on external data sources (e.g. logfiles)
-> newrelic-like agents that auto-export streams on demand
-> on demand streams :)
-> nagios adapter for alerting
-> http interface? (need to bundle lotsa resources)
-> stream replication
-> optimized for seeks over time ranges
-> row compression / page compression?
-> generate embed snippets from ruby api -> rails helper plugin
-> execute multiple queries in parallel in the ui -> get multiple timeseries
   and tables (tabs)
